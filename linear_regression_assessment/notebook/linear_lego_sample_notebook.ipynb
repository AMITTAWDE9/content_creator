{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Lego Collector's Dilemma  \n",
    "\n",
    "## Problem statement\n",
    "\n",
    "You are a die hard Lego enthusiast wishing to collect as many board sets as you can. But before that you wish to be able to predict the price of a new lego product before its price is revealed so that you can budget it from your revenue. Since (luckily!), you are a data scientist in the making, you wished to solve this problem yourself. This dataset contains information on lego sets scraped from lego.com. Each observation is a different lego set with various features like how many pieces in the set, rating for the set, number of reviews per set etc. Your aim is to build a linear regression model to predict the price of a set.\n",
    "\n",
    "\n",
    "## About the Dataset:\n",
    "The snapshot of the data, you will be working on :\n",
    "\n",
    "![Dataset](../images/lego_data.PNG)\n",
    "\n",
    "You can see that some of the features of `review_difficulty`, `theme_name` and `Country Name` in the data are textual in nature. Don't worry, we have made things simple for you with some behind-the-scenes data preprocessing.  We have also modified the feature of `age`. You will be learning about all these preprocessing techinques in a later concept. For now let us concentrate on getting those Lego sets in your hands soon. :) \n",
    "\n",
    "![Dataset](../images/new_le.png)\n",
    "\n",
    "\n",
    "\n",
    "## Why solve this project ?\n",
    "\n",
    "After completing this project, you will have the better understanding of how to build a linear regression model. In this project, you will apply the following concepts.\n",
    "\n",
    " \n",
    "- Train-test split\n",
    "- Correlation between the features \n",
    "- Linear Regression\n",
    "- MSE and $R^2$ Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and splitting (A complete task)\n",
    "\n",
    "In this task, we will load the data and take a look at the features and target variable.\n",
    "\n",
    "We will also split the data into train set and test set for further processing.\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* The path for the dataset file has been store in variable `path`\n",
    "* Load dataset using pandas read_csv api in variable `df`\n",
    "* Display first 5 columns of dataframe `df`.\n",
    "* Store all the features(independent values) in  a variable called `X`\n",
    "* Store the target variable (dependent value) in a variable called `y`\n",
    "* Split the dataframe into `X_train,X_test,y_train,y_test` using `train_test_split()` function. Use `test_size = 0.3` and `random_state = 6 `\n",
    "\n",
    "\n",
    "## Hints\n",
    "\n",
    "* Use `X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=6)` to split the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ages  list_price  num_reviews  piece_count  play_star_rating  \\\n",
      "0    19       29.99            2          277               4.0   \n",
      "1    19       19.99            2          168               4.0   \n",
      "2    19       12.99           11           74               4.3   \n",
      "3     5       99.99           23         1032               3.6   \n",
      "4     5       79.99           14          744               3.2   \n",
      "\n",
      "   review_difficulty  star_rating  theme_name  val_star_rating  country  \n",
      "0                  0          4.5           0              4.0       20  \n",
      "1                  2          5.0           0              4.0       20  \n",
      "2                  2          4.3           0              4.1       20  \n",
      "3                  0          4.6           1              4.3       20  \n",
      "4                  1          4.6           1              4.1       20  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import header files\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv(\"../data/lego_final.csv\")\n",
    "\n",
    "# Print first five columns\n",
    "print(df.head())\n",
    "\n",
    "# Store independent variable\n",
    "X = df.drop('list_price',axis=1)\n",
    "\n",
    "# Store dependent variable\n",
    "y = df['list_price']\n",
    "\n",
    "# Split the dataset\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y ,test_size=0.3,random_state=6)\n",
    "\n",
    "# code ends here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictor Check \n",
    "\n",
    "In this task, we will plot the `scatter_plot` for different features vs target variable.  \n",
    "\n",
    "This will help us identify which features are highly correlated with the target variable. \n",
    "   \n",
    "\n",
    "### Things to ponder upon (Additional subheading for visualization purposes)\n",
    "\n",
    "- Which of these features would be the best predictor for estimating our target variable?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce feature redundancies! \n",
    "\n",
    "In this task, we will try to find correlation among features by keeping an inter-feature correlation threshold of `0.75`. If two features are correlated with a value greater than `|0.75|`, we will remove one of them. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is my price prediction ok?\n",
    "\n",
    "\n",
    "In this task, we will be using linear regression to predict the price. \n",
    "We will load the `sklearn` model of linear regression, train it on train data and predict the outcomes of test data\n",
    "\n",
    "We will then check the model accuracy using `r^2 score` and `mse`. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
